{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asteroid-team/asteroid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GC3BHFyJ70a",
        "outputId": "4f45cc60-6154-4c6e-a61e-09b4fff63ae2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'asteroid'...\n",
            "remote: Enumerating objects: 7684, done.\u001b[K\n",
            "remote: Counting objects: 100% (307/307), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 7684 (delta 143), reused 248 (delta 111), pack-reused 7377\u001b[K\n",
            "Receiving objects: 100% (7684/7684), 5.98 MiB | 4.92 MiB/s, done.\n",
            "Resolving deltas: 100% (4838/4838), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "sMcTU0XZ4L-3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read\n",
        "from asteroid.models import BaseModel\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_SISNRi(src_ref, src_est, mix):\n",
        "\n",
        "    \"\"\"\n",
        "        Calculate Scale-Invariant Source-to-Noise Ratio improvement (SI-SNRi)\n",
        "        Args:\n",
        "            src_ref: numpy.ndarray, [C, T]\n",
        "            src_est: numpy.ndarray, [C, T], reordered by best PIT permutation\n",
        "            mix: numpy.ndarray, [T]\n",
        "        Returns:\n",
        "            average_SISNRi\n",
        "    \"\"\"\n",
        "\n",
        "    sisnr1 = cal_SISNR(src_ref[0], src_est[0])\n",
        "    #print(\"SISNR 1\", sisnr1)\n",
        "    sisnr2 = cal_SISNR(src_ref[1], src_est[1])\n",
        "    #print(\"SISNR 2\", sisnr2)\n",
        "\n",
        "    sisnr1b = cal_SISNR(src_ref[0], mix)\n",
        "    #print(\"SISNR 1b\", sisnr1b)\n",
        "\n",
        "    sisnr2b = cal_SISNR(src_ref[1], mix)\n",
        "    #print(\"SISNR 2b\", sisnr2b)\n",
        "\n",
        "    avg_SISNRi = ((sisnr1 - sisnr1b) + (sisnr2 - sisnr2b)) / 2\n",
        "\n",
        "    return avg_SISNRi\n",
        "\n",
        "def cal_SISNR(ref_sig, out_sig, eps=1e-8):\n",
        "\n",
        "    \"\"\"\n",
        "        Calcuate Scale-Invariant Source-to-Noise Ratio (SI-SNR)\n",
        "        Args:\n",
        "            ref_sig: numpy.ndarray, [T]\n",
        "            out_sig: numpy.ndarray, [T]\n",
        "        Returns:\n",
        "            SISNR\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(ref_sig) == len(out_sig)\n",
        "\n",
        "    ref_sig = ref_sig - np.mean(ref_sig)\n",
        "    out_sig = out_sig - np.mean(out_sig)\n",
        "\n",
        "    ref_energy = np.sum(ref_sig ** 2) + eps\n",
        "\n",
        "    proj = np.sum(ref_sig * out_sig) * ref_sig / ref_energy\n",
        "\n",
        "    noise = out_sig - proj\n",
        "\n",
        "    #ratio = np.sum(proj ** 2) / (np.sum(noise ** 2) + eps)\n",
        "    ratio = ref_energy / (np.sum(noise ** 2) + eps)\n",
        "\n",
        "    sisnr = 10 * np.log10(ratio + eps)\n",
        "\n",
        "    return sisnr\n",
        "\n",
        "def data_prep(path_orig1, path_orig2, path_est_1, path_est_2, path_mix):\n",
        "\n",
        "    \"\"\"\n",
        "        Convert input .wav files to the right numpy arrays for cal_SISNRi\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    orig_1 = read(path_orig1)\n",
        "    orig_2 = read(path_orig2)\n",
        "    est_1 = read(path_est_1)\n",
        "    est_2 = read(path_est_2)\n",
        "    mix = read(path_mix)\n",
        "\n",
        "    src_ref = np.vstack((np.array(orig_1[1]), np.array(orig_2[1])))\n",
        "    src_est = np.vstack((np.array(est_1[1]), np.array(est_2[1])))\n",
        "    mix = np.array([mix[1]])\n",
        "    mix = np.squeeze(mix)\n",
        "\n",
        "    return src_ref, src_est, mix\n",
        "\n",
        "def separate(path_mix):\n",
        "\n",
        "    \"\"\"\n",
        "        Separate mixture file and return the two paths to the separated files\n",
        "    \"\"\"\n",
        "    model.separate(path_mix, force_overwrite=True)\n",
        "    path_est_1 = \"/\" + path_mix[1:-4] + '_est1.wav' \n",
        "    path_est_2 = \"/\" + path_mix[1:-4] + '_est2.wav' \n",
        "    \n",
        "    return path_est_1, path_est_2"
      ],
      "metadata": {
        "id": "j1iT06-14miI"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: Path to folder with mixtures, path to folder with s1, path to folder with s2\n",
        "path_mixtures = \"/content/mix_2/\"\n",
        "path_s1 = \"/content/s1/\"\n",
        "path_s2 = \"/content/s2/\""
      ],
      "metadata": {
        "id": "8GTny43AfUTC"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over files in that directory\n",
        "paths_s1 = []\n",
        "for filename in os.listdir(path_s1):\n",
        "    f = os.path.join(path_s1, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        #print(f)\n",
        "        paths_s1.append(f)\n",
        "\n",
        "paths_s2 = []\n",
        "for filename in os.listdir(path_s2):\n",
        "    f = os.path.join(path_s2, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        #print(f)\n",
        "        paths_s2.append(f)\n",
        "\n",
        "paths_mixtures = []\n",
        "for filename in os.listdir(path_mixtures):\n",
        "    f = os.path.join(path_mixtures, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        #print(f)\n",
        "        paths_mixtures.append(f)"
      ],
      "metadata": {
        "id": "wg-mO3LQfVS9"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "\n",
        "model = BaseModel.from_pretrained(\"mpariente/DPRNNTasNet-ks2_WHAM_sepclean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8XjwVLC8YE",
        "outputId": "fcdfc9d6-844f-41f9-d337-8f399ab9d421"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py:597: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SISNRi = []\n",
        "for i, path_mix in enumerate(paths_mixtures):\n",
        "  path_est_1, path_est_2 = separate(paths_mixtures[i])\n",
        "  src_ref1, src_est1, mix1 = data_prep(paths_s1[i], paths_s2[i], path_est_1, path_est_2, path_mix)\n",
        "  src_ref2, src_est2, mix2 = data_prep(paths_s1[i], paths_s2[i], path_est_2, path_est_1, path_mix)\n",
        "\n",
        "  avg_SISNRi_1 = cal_SISNRi(src_ref1, src_est1, mix1)\n",
        "  avg_SISNRi_2 = cal_SISNRi(src_ref2, src_est2, mix2)\n",
        "\n",
        "  SISNRi.append(max(avg_SISNRi_1, avg_SISNRi_2))\n",
        "\n",
        "  print(\"Progress:\", int(((i+1)/len(paths_mixtures))*100), \"%\")\n",
        "  #print(SISNRi)\n",
        "\n",
        "SISNRi = np.array(SISNRi)\n",
        "print(\"SISNRi: \", SISNRi.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taHwDltqfhOZ",
        "outputId": "e2e3b688-fd27-4282-fa8a-0f2e112c88a9"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 5 %\n",
            "Progress: 10 %\n",
            "Progress: 15 %\n",
            "Progress: 20 %\n",
            "Progress: 25 %\n",
            "Progress: 30 %\n",
            "Progress: 35 %\n",
            "Progress: 40 %\n",
            "Progress: 45 %\n",
            "Progress: 50 %\n",
            "Progress: 55 %\n",
            "Progress: 60 %\n",
            "Progress: 65 %\n",
            "Progress: 70 %\n",
            "Progress: 75 %\n",
            "Progress: 80 %\n",
            "Progress: 85 %\n",
            "Progress: 90 %\n",
            "Progress: 95 %\n",
            "Progress: 100 %\n",
            "SISNRi:  13.25061246981647\n"
          ]
        }
      ]
    }
  ]
}